structure
 - intro
   - two things to remember
   - premise: automated testing is good
   - problems with automated acceptance testing
   - what is sdd?
 - example
   - example process and application
   - show two scenarios
   - introduce new story
   - show where it affects scenarios
   - discuss things that don't go in the scenarios
   - walk through process for implementing
 - concerns
   - how to drive system
   - fixture code
   - design of underlying code
   - analysis/vision stuff
   - QA/Dev coordination
   - technologies
   - dealing with failing scenarios
 - Twist demo
   - sales pitch
   - refactoring
   - reuse and intellisense
   - drivers
   - recording implementations
   - organizing scenarios
   - show unimplemented stuff
 - outro
   - twist
   - acknowledgements
   - sdd summary
   - two things to remember

new
 - first scenario: walking skeleton
 - possibility of non-automated approach
 - workflow vs actor layer
 - definition: readable by everyone

todo
 - refer to 'customer tests'
 - insert refs to slides
 - move acks to intro

collaboration in defining scenarios
 - tools (e.g. twist, cucumber) can be used to help this
 - or through discussion and just use code

tensions
 - speed
 - readability
 - impression of application and what is important
 - coverage
 - completeness
 - maintenance effort
 - reliability

Old acks

Simon Stewart taught me how to model the application in my tests. He
also wrote WebDriver which is a great service to the human race.

Dan Bodart made me understand what it really means to make an
application testable.

Gitanjali Venkatraman is the best tester I have ever worked with. A
lot of my ideas about collaboration between testers and developers
come from watching her work.

Ian Cartwright once gave me a stern talking to about an application
that I was working on. I haven't been the same since.

