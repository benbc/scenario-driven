Example
-------

*Project*

I'm going to talk through how scenario-driven development works in
practice. I want to put that into a realistic context, so I'm going to
describe an example project and explain how the team uses scenarios to
frame their development process.

First, let me introduce you to the team. This is Parvinder, the
project manager; he spends a lot of time worrying and fiddling with
spreadsheets -- we won't have much more to do with him. This is
Bethany, the business analyst; she is responsible for understanding
the customers' needs and turning them into words of one syllable that
the rest of the team understand. This is Terrance, the tester; he
helps Bethany write the acceptance criteria for the stories, helps the
developers implement the stories and finally checks that everything is
working properly -- it rather sounds like he does all the work. And
these are Doreen, Delilah and Dave; as you will have guessed, they are
the developers; they write code.

The team are using an XP-ish agile process. They work closely with the
customer (here's the customer, he's called Cesar) to understand what
the application needs to do. These requirements are expressed as
stories, which have a narrative and brief acceptance criteria. Much of
the understanding of the stories is a shared, social understanding
amongst the members of the team rather than being rigorously
documented. The whole team is involved, to some extent, throughout the
development process, collaborating and ensuring that everyone shares
an understanding of where the application is headed.

The application the team is working on is an online banking app. It
allows the bank's customers to see their statements, make payments,
all the usual sort of stuff.

*Scenarios*

As well as unit tests, and the odd integration test to check the
interaction between their code and external systems, the team has a
set of scenario tests which describe the main activities that the
application supports. I'm going to show you a couple of their
scenarios.

The ownership of these scenarios is shared amongst the team. Bethany
(the BA) is responsible for what the scenarios should be, that is to
say for agreeing with Cesar (the customer) what activities the
application supports and how the application will be used. Terrance
decides exactly what the workflow of each scenario is and owns their
textual description. Doreen, Delilah and Dave write the code that
automate the scenarios.

This is the "Patricia Pays her Phone Bill" scenario. It describes a
customer, Patricia, transferring the money from a savings account to
her current account entering the payment details, submitting it and
finally going back to their home page to see that her account has been
debited. When this scenario is run it will, through the magic of code,
get the application into the right state for the scenario, drive the
application through the workflow and ensure that it behaves as
expected.

This context describes the necessary prerequisites for the scenario to
run: the application is running, Patricia is provisioned on the system
and has enough money in her account to make the payment successfully.

And here is another scenario: "Pierre Wonders Why He's So
Poor". Pierre looks at the statement for his account, filters it to
show out-goings only, gives a little moan of despair and then follows
a link to find out about low-rate loans.

There are several other scenarios, but not a huge number. Each one
describes how the users of the system will carry out some important
activity. The scenarios are aligned with those activities rather than
with the functionality that they exercise. For example there isn't a
"Transfers" scenario, although the ability to make transfers between
accounts is an important feature of the system. But the scenarios are
at a higher level than that -- they describe the motivations behind
the application as well as how it works.

The scenarios were roughly sketched out right at the beginning of the
project, by Bethany and Cesar, before they drilled down into the
features that would need to go into the application. They've been used
to guide the whole team since then: to help define and prioritize
features, to ensure the team shares an understanding of what the
application is for and, through their embodiment as automated tests,
to ensure that the application really does support the activities it
has been designed for.

*A story*

So what happens when the team plays a new story? Here is the story
they're working on now: "Stop account going overdrawn".

  In order that I can control who I make loans to,
  as a Bank Manager,
  I want payments which would cause accounts to go overdrawn to fail.

(You understand that this is pretty early in the development off the
application.)

So the system will support overdrafts, but they haven't been
implemented yet. For now it is just going to deny attempts to make an
account go overdrawn. Here are the acceptance criteria:

* A payment that would make the account go overdrawn fails.
* A message is displayed to the customer explaining what went wrong.
* The customer stays on the payment page with the fields of the form
  all filled in.
* No money is taken out of the account.
* A payment which leaves the account empty is successful.

*Updating the scenarios*

When this story is played, Terrance (the tester) needs to think about
how it affects the scenarios. In the "Patricia Pays her Phone Bill"
scenario, we saw Patricia transfer money into her current account in
order to make the payment. Here's an opportunity to exercise this new
functionality: Patricia can try to make the payment before there is
enough money in her current account to do so.

Note that we probably don't want to create a new failing payment
scenario. There are two good reasons for this. Failing to make a
payment probably isn't one of the activities that Cesar particularly
wants to support. This is not to say that the functionality to stop
people going overdrawn isn't important, it is, but isn't in itself a
motivating force behind the system.

There is another reason for keeping the number of scenarios small. In
order that they are realistic tests of the whole system, they may need
to be relatively slow. They may have to bring up servers, make network
or database calls and so on. It is important to keep the tests as fast
as is reasonably possible (and I'll talk about some techniques to help
with that later), but they can't be edge-to-edge system tests and
still remain as lightning fast as unit tests.

So Terrence updates "Patricia pays her Phone Bill" to reflect the new
functionality. A new section of the test sees Patricia trying to make
the payment before she has transferred the money from her savings
account. The payment fails and she sees a message explaining why.

Note that this updated scenario doesn't reflect all the acceptance
criteria on the story. This is one of the points where you have to be
careful when deciding what to put into the scenarios (and this is one
of the two main ideas that I want to pass on to you today -- that what
you leave out of your tests is as important as what you put in). We
don't test that no money has come out of the account; we don't check
that the fields are all still filled in (we also don't have a test for
the edge case of bringing the balance down to zero).

This is not to say that these acceptance criteria will not have
automated tests. They will, but those tests will be lower-level tests,
maybe unit tests, targeted at the components of the system responsible
for enforcing the behaviour. The main reason is that we don't want to
clutter up the scenarios with details and edge cases. We want them to
be a clear description of the intent of the system and the activities
it supports.

One thing people say about Test Driven Development is that "it's not
about the tests", it's about the rigour of the process and the design
that the tests drive out. In the same way you could say that Scenario
Drive Development isn't about the tests, it's about the shared
understanding of the system that they bring to the team. Obviously the
automated tests that are a byproduct of both approaches are extremely
valuable and we wouldn't want to be without them.

Now one part of this scenario, where it checks for the message,
is completely new. The message wasn't there before, so the code
underlying the scenario won't yet support checking for its
presence. That code needs to be written.

I should point out that there is code underlying these scenarios. This
is a screenshot from Twist, a tool produced by ThoughtWorks Studios
which allows scenarios written in this way to be mapped directly onto
code. More excitingly it is actually a refactoring IDE for tests. This
scenario, and the underlying code, can be refactored just as you would
refactor normal code. I'll talk more about Twist later and show it to
you in action. I'll also talk about other technologies that can be
used.

So right now, in our story, this scenario *fails*. In fact it doesn't
even compile. To get it compiling, and eventually passing, we need to
turn to Doreen, Delilah and Dave.

*Implementing the story*

Before we talk about the process for implementing the story, We need
to stop and talk about how the test harness for the scenarios is
structured. The approach I'm going to describe is roughly technology
agnostic.

The top layer is the scenarios themselves. They sit on top of a
workflow layer which models the process of using the application. In
our scenario when we see Patricia going to the payments page, this
maps onto a method in a workflow. The workflow layer is an
implementation of the concepts needed for defining the scenarios. It
is written in terms of a application model; for a GUI application this
is typically written as a number of page or screen objects, each one
of which represents a single page in the application (or screen for a
thick client). This page model captures how the user interacts with
the pages and what the flow between them looks like. It hides the
details of the code that we are using to drive the application. For
example in a web application, the page objects have an interface
written in terms of what the user sees (buttons clicked, fields filled
in, links followed), whereas its implementation is written in terms of
HTML elements and XPath expressions. This implementation will
typically use a library designed for driving GUI apps, like Selenium,
Watir, White or Abbot.

Let's look at who has responsibility for these layers. Bethany (the
business analyst) and Terrence are responsible for the contents of the
scenario layer. Terrance can change the scenarios as he needs to. If
his changes are already supported by the workflow layer then he's
done. (Of course the tests will probably fail when they're changed,
but the developers only have to concern themselves with the
application code.)

The implementation of the workflow layer in terms of the application
model is also Terrence's domain. He cares that the application model
is a faithful representation of how the application looks to a
user. But he probably won't write this stuff himself; he'll pair on
writing it with a developer (I think this is Delilah, they are hard to
tell apart). Between them they will ensure that the code accurately
models the application and that it is reasonably efficient and easy to
implement in the layer below.

After that it's developers all the way down. The developers own the
code in the application layer and of course the application itself.

So during the development of a story, Delilah first pairs with
Terrence to fill in the code under the scenario, then she pairs with
Dave to finish the test code. Finally they turn to the application
code.

Notice that as well as using the scenario to drive the functionality
of the code that is being written, we are also using the test harness
that underlies it to drive the details of the UI. For example we are
writing XPath expressions in our page objects before we write the HTML
that they will be querying. This forces us to consider testability at
the application and UI level in the same way that TDD does at the
object level.

Concerns
--------

analysis/vision
shared vision -- back to essence/projection
qa/dev coordination
failing scenarios?
driving points
tech for scenarios
design of harness
 - fixture
 - workflow vs actor
