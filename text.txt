Example
-------

*Project*

I'm going to talk through how scenario-driven development works in
practice. I want to put that into a realistic context, so I'm going to
describe an example project and explain how the team uses scenarios to
frame their development process.

First, let me introduce you to the team. This is Parvinder, the
project manager; he spends a lot of time worrying and fiddling with
spreadsheets -- we won't have much more to do with him. This is
Bethany, the business analyst; she is responsible for understanding
the customers' needs and turning them into words of one syllable that
the rest of the team understand. This is Terrance, the tester; he
helps Bethany write the acceptance criteria for the stories, helps the
developers implement the stories and finally checks that everything is
working properly -- it rather sounds like he does all the work. And
these are Doreen, Delilah and Dave; as you will have guessed, they are
the developers; they write code.

The team are using an XP-ish agile process. They work closely with the
customer (here's the customer, he's called Cesar) to understand what
the application needs to do. These requirements are expressed as
stories, which have a narrative and brief acceptance criteria. Much of
the understanding of the stories is a shared, social understanding
amongst the members of the team rather than being rigorously
documented. The whole team is involved, to some extent, throughout the
development process, collaborating and ensuring that everyone shares
an understanding of where the application is headed.

The application the team is working on is an online banking app. It
allows the bank's customers to see their statements, make payments,
all the usual sort of stuff.

*Scenarios*

As well as unit tests, and the odd integration test to check the
interaction between their code and external systems, the team has a
set of scenario tests which describe the main activities that the
application supports. I'm going to show you a couple of their
scenarios.

The ownership of these scenarios is shared amongst the team. Bethany
(the BA) is responsible for what the scenarios should be, that is to
say for agreeing with Cesar (the customer) what activities the
application supports and how the application will be used. Terrance
decides exactly what the workflow of each scenario is and owns their
textual description. Doreen, Delilah and Dave write the code that
automate the scenarios.

This is the "Patricia Pays her Phone Bill" scenario. It describes a
customer, Patricia, transferring the money from a savings account to
her current account entering the payment details, submitting it and
finally going back to their home page to see that her account has been
debited. When this scenario is run it will, through the magic of code,
get the application into the right state for the scenario, drive the
application through the workflow and ensure that it behaves as
expected.

This context describes the necessary prerequisites for the scenario to
run: the application is running, Patricia is provisioned on the system
and has enough money in her account to make the payment successfully.

And here is another scenario: "Pierre Wonders Why He's So
Poor". Pierre looks at the statement for his account, filters it to
show out-goings only, gives a little moan of despair and then follows
a link to find out about low-rate loans.

There are several other scenarios, but not a huge number. Each one
describes how the users of the system will carry out some important
activity. The scenarios are aligned with those activities rather than
with the functionality that they exercise. For example there isn't a
"Transfers" scenario, although the ability to make transfers between
accounts is an important feature of the system. But the scenarios are
at a higher level than that -- they describe the motivations behind
the application as well as how it works.

The scenarios were roughly sketched out right at the beginning of the
project, by Bethany and Cesar, before they drilled down into the
features that would need to go into the application. They've been used
to guide the whole team since then: to help define and prioritize
features, to ensure the team shares an understanding of what the
application is for and, through their embodiment as automated tests,
to ensure that the application really does support the activities it
has been designed for.

*A story*

So what happens when the team plays a new story? Here is the story
they're working on now: "Stop account going overdrawn".

  In order that I can control who I make loans to,
  as a Bank Manager,
  I want payments which would cause accounts to go overdrawn to fail.

(You understand that this is pretty early in the development off the
application.)

So the system will support overdrafts, but they haven't been
implemented yet. For now it is just going to deny attempts to make an
account go overdrawn. Here are the acceptance criteria:

* A payment that would make the account go overdrawn fails.
* A message is displayed to the customer explaining what went wrong.
* The customer stays on the payment page with the fields of the form
  all filled in.
* No money is taken out of the account.
* A payment which leaves the account empty is successful.

*Updating the scenarios*

When this story is played, Terrance (the tester) needs to think about
how it affects the scenarios. In the "Patricia Pays her Phone Bill"
scenario, we saw Patricia transfer money into her current account in
order to make the payment. Here's an opportunity to exercise this new
functionality: Patricia can try to make the payment before there is
enough money in her current account to do so.

Note that we probably don't want to create a new failing payment
scenario. There are two good reasons for this. Failing to make a
payment probably isn't one of the activities that Cesar particularly
wants to support. This is not to say that the functionality to stop
people going overdrawn isn't important, it is, but isn't in itself a
motivating force behind the system.

There is another reason for keeping the number of scenarios small. In
order that they are realistic tests of the whole system, they may need
to be relatively slow. They may have to bring up servers, make network
or database calls and so on. It is important to keep the tests as fast
as is reasonably possible (and I'll talk about some techniques to help
with that later), but they can't be edge-to-edge system tests and
still remain as lightning fast as unit tests.

So Terrence updates "Patricia pays her Phone Bill" to reflect the new
functionality. A new section of the test sees Patricia trying to make
the payment before she has transferred the money from her savings
account. The payment fails and she sees a message explaining why.

Note that this updated scenario doesn't reflect all the acceptance
criteria on the story. This is one of the points where you have to be
careful when deciding what to put into the scenarios (and this is one
of the two main ideas that I want to pass on to you today -- that what
you leave out of your tests is as important as what you put in). We
don't test that no money has come out of the account; we don't check
that the fields are all still filled in (we also don't have a test for
the edge case of bringing the balance down to zero).

This is not to say that these acceptance criteria will not have
automated tests. They will, but those tests will be lower-level tests,
maybe unit tests, targeted at the components of the system responsible
for enforcing the behaviour. The main reason is that we don't want to
clutter up the scenarios with details and edge cases. We want them to
be a clear description of the intent of the system and the activities
it supports.

One thing people say about Test Driven Development is that "it's not
about the tests", it's about the rigour of the process and the design
that the tests drive out. In the same way you could say that Scenario
Drive Development isn't about the tests, it's about the shared
understanding of the system that they bring to the team. Obviously the
automated tests that are a byproduct of both approaches are extremely
valuable and we wouldn't want to be without them.

Now one part of this scenario, where it checks for the message,
is completely new. The message wasn't there before, so the code
underlying the scenario won't yet support checking for its
presence. That code needs to be written.

I should point out that there is code underlying these scenarios. This
is a screenshot from Twist, a tool produced by ThoughtWorks Studios
which allows scenarios written in this way to be mapped directly onto
code. More excitingly it is actually a refactoring IDE for tests. This
scenario, and the underlying code, can be refactored just as you would
refactor normal code. I'll talk more about Twist later and show it to
you in action. I'll also talk about other technologies that can be
used.

So right now, in our story, this scenario *fails*. In fact it doesn't
even compile. To get it compiling, and eventually passing, we need to
turn to Doreen, Delilah and Dave.

*Implementing the story*

Before we talk about the process for implementing the story, We need
to stop and talk about how the test harness for the scenarios is
structured. The approach I'm going to describe is roughly technology
agnostic.

The top layer is the scenarios themselves. They sit on top of a
workflow layer which models the process of using the application. In
our scenario when we see Patricia going to the payments page, this
maps onto a method in a workflow. The workflow layer is an
implementation of the concepts needed for defining the scenarios. It
is written in terms of a application model; for a GUI application this
is typically written as a number of page or screen objects, each one
of which represents a single page in the application (or screen for a
thick client). This page model captures how the user interacts with
the pages and what the flow between them looks like. It hides the
details of the code that we are using to drive the application. For
example in a web application, the page objects have an interface
written in terms of what the user sees (buttons clicked, fields filled
in, links followed), whereas its implementation is written in terms of
HTML elements and XPath expressions. This implementation will
typically use a library designed for driving GUI apps, like Selenium,
Watir, White or Abbot.

Let's look at who has responsibility for these layers. Bethany (the
business analyst) and Terrence are responsible for the contents of the
scenario layer. Terrance can change the scenarios as he needs to. If
his changes are already supported by the workflow layer then he's
done. (Of course the tests will probably fail when they're changed,
but the developers only have to concern themselves with the
application code.)

The implementation of the workflow layer in terms of the application
model is also Terrence's domain. He cares that the application model
is a faithful representation of how the application looks to a
user. But he probably won't write this stuff himself; he'll pair on
writing it with a developer (I think this is Delilah, they are hard to
tell apart). Between them they will ensure that the code accurately
models the application and that it is reasonably efficient and easy to
implement in the layer below.

After that it's developers all the way down. The developers own the
code in the application layer and of course the application itself.

So during the development of a story, Delilah first pairs with
Terrence to fill in the code under the scenario, then she pairs with
Dave to finish the test code. Finally they turn to the application
code.

Notice that as well as using the scenario to drive the functionality
of the code that is being written, we are also using the test harness
that underlies it to drive the details of the UI. For example we are
writing XPath expressions in our page objects before we write the HTML
that they will be querying. This forces us to consider testability at
the application and UI level in the same way that TDD does at the
object level.

Driving everything
------------------

I intend that the idea of driving development with scenarios should be
taken very seriously and should start right at the beginning. I think
that sketching out a candidate set of activities that the application
will support should be pretty much the first piece of analysis that is
carried out on a project. This set of activities, and the scenarios
that illustrate them, act as a manifesto for the project. They enable
the customers to clarify what they want from the application and
provide a vision for the application which is shared amongst the team.

The scenarios are not *just* *tests*. Their identity, purpose and flow
should be familiar to everyone on the team; and the team, including
the customer, should evolve them together during the project. They are
the clearest, high-level, localized statement of what the application
*is*.

Any application has a notional, abstract form which captures what the
application *is*, it's essence. Unfortunately this essence isn't
written down anywhere where everyone can see it. Presumably it is this
essence that vast requirements documents are supposed to capture, but
of course they fail because, while they are long, they can't be
correct and they can't adapt as we learn things during development.

Instead of being able to point at the essence, it has to be taken on
trust. I suspect that, if we could measure it, we would find that the
extent to which the members of a team share a view of this essence
(and the extent to which their view is clear and complete) is a strong
indicator of the success of a project.

We can't see the essence, but we can see *projections* of it into
various media. Each of these projections is incomplete and distorted,
because of the nature of the media into which it is made. When you
project a three-dimension object into two-dimensional space in order
to draw it, you make a decision about how to make the projection in
order to best show what you want. But which ever projection you chose
distorts the original object to some extent, misrepresents it and
leaves out some details.

The most obvious projection of an application's essence is the
code. But while there may be a lot of it, it's not complete (it
doesn't include the behaviour of the people who use the software, or
the environment that it runs in). And there maybe so much of it that
it isn't clear what the sum of the parts comes to.

Other projections of the essence include the documentation, the unit
tests, maybe even the marketing material. The complete set of
implemented stories is another projection.

An individual story can be seen as a delta to the essence. A
well-written story steers clear of talking about the implementation;
in a team where the UI design work is incorporated into the
development it may even avoid too many details about the interface. So
what it talks about is the essence. And when any member of the team
reads the story they naturally project that essence into the medium
that they are most familiar with. The UI designer sees how the flow of
the UI needs to change to accommodate some new widget; the tester
imagines the edge cases and interactions that need testing; the
developers can see which modules in the code need to change; the
technical writer knows immediately which sections of the documentation
need to be updated.

And of course the scenarios are just one more projection. But they are
an interesting one. They are rather abstracted from the details of the
implementation. They are a projection into a rather rarified medium
which exists only to accommodate that project. And they are shared
amongst the entire team, written in a language that everyone can
understand. When a new story is played, everyone should agree on the
affect of it on the scenarios, rather than having their own private
view. So perhaps the scenarios are the closest thing we have to a
faithful projection of the essence (although of course we pay a price
in the paucity of detail).

The process of developing an application can be framed in terms of
elaboration of the application's scenarios. The identity of the
scenarios remains roughly constant during development, but their
content evolves. That evolution, and the particular scenarios that are
evolving, provide themes for the team during a project. "This
iteration we are going to fill in the details of the recurring
payments scenario." "This release focuses on improving the useability
of the admin scenarios."

Concerns
--------

I now want to talk about some of the forces that are at play and
decisions that need to be taken if you take a scenario-driven
approach.

Earlier I described a close collaboration between testers and
developers, pairing to write the code behind the scenarios. I would
like to take that collaboration further and maintain it throughout the
development of a story. I talked about leaving some aspects of the
story's acceptance criteria to be tested by lower-level tests -- unit
tests, integration tests. As well as pairing on the scenarios,
developers and testers can pair on writing these tests, to give the
tester confidence that the tests do what they need to. And as the
story is implemented, piece by piece, the developers let the tester
know what has been checked in, what should be working correctly (and
that he can test) and what has not yet been implemented. This way, by
the time the developers are finished (or a very short while after) the
tester is finished with the story too.

failing scenarios?
driving points
tech for scenarios
design of harness
 - fixture
 - workflow vs actor

Outro
-----

*Acknowledgements*

I want to acknowledgement some of the people who have been most
influential on my thinking in this area and point you in their
direction to find out more.

Nat Pryce and Steve Freeman's book gives a better account of how to
use tests to drive the coding process than I could hope to do. All
developers should have read it.

Simon Stewart taught me how to model the application in my tests. He
also wrote WebDriver which is a great service to the human race.

Dan Bodart made me understand what it really means to make an
application testable.

Gitanjali Venkatraman is the best tester I have ever worked with. A
lot of my ideas about collaboration between testers and developers
come from watching her work.

Ian Cartwright once gave me a stern talking to about an application
that I was working on. I haven't been the same since.

And as you will have spotted if you are familiar with them, the idea
of scenarios that I presented is heavily influenced by Jeff Patton's
writing on story mapping.
